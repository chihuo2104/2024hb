from flask import Flask, request
from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig
model = AutoModelForCausalLM.from_pretrained('roneneldan/TinyStories-33M')
tokenizer = AutoTokenizer.from_pretrained("EleutherAI/gpt-neo-125M")
app = Flask(__name__)


@app.route('/')
def index():
    return '''
<!doctype html>
<html>
<head>
    <title>å¤èµ›æµ‹è¯•ç³»ç»Ÿ</title>
</head>
<body>
<h1>è¿™æ˜¯æ¥è‡ªchiçš„æµ‹è¯•ç³»ç»Ÿ</h1>
<h1>ä½¿ç”¨ä½ çš„èªæ˜æ‰æ™ºï¼Œéª—è¿‡AIå§</h1>
<hr/>
<h2>åœ¨è¿™é‡Œè¾“å…¥ä½ çš„å°ä½œæ–‡</h2>
<textarea id="input" style="width:80%;height:20%"></textarea>
<div id="resp"></div>
<script>
  async function commit () {
    content = document.getElementById("input").value
    r = document.getElementById("resp")
    resp = await fetch('/test?input=' + encodeURIComponent(content))
    res = await resp.text()
    r.innerHTML += (new Date() + 'æ‚¨çš„è¾“å…¥:' + content +  'è¿”å›å†…å®¹ï¼š' + res) + "<br/>"
  }
</script><br/>
<button onclick="commit()">ç‚¹æˆ‘æäº¤</button>
</body>
</html>
    '''
@app.route('/test')
def predict():
    res = request.args.get('input')
    prompt = res
    input_ids = tokenizer.encode(prompt, return_tensors="pt")
    output = model.generate(input_ids, max_length = 1000, num_beams=1)
    output_text = tokenizer.decode(output[0], skip_special_tokens=True)
    resp = output_text[len(prompt):]
    resp = resp.lower()
    print(resp)
    score = 0
    if resp.find("good") != -1 :
        score += 30
    if resp.find("great") != -1:
        score += 30
    if resp.find("awesome") != -1:
        score += 20
    if resp.find("chihuo2104") != -1:
        score += 10
    if resp.find("nekovanilla") != -1:
        score += 5
    if resp.find("ğŸ¢") != -1:
        score += 5
    return "æ‚¨çš„åˆ†æ•°ï¼š" + str(score) + "\nè¿”å›æ–‡æœ¬ï¼š" + resp
app.run(host='0.0.0.0', port=5000)